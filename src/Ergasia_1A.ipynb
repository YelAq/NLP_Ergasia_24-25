{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e181c2",
   "metadata": {},
   "source": [
    "# Text 1's sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a925d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'very', 'appreciated', 'the', 'full', 'support', 'of', 'the', 'professor', ',', 'for', 'our', 'Springer', 'proceedings', 'publication']\n",
      "ROLES\n",
      "{'I': 'PRP', 'am': 'BVP', 'very': 'RB', 'appreciated': 'VBN', 'the': 'DT', 'full': 'JJ', 'support': 'NN', 'of': 'IN', 'professor': 'NN', ',': 'PUNC', 'for': 'IN', 'our': 'PRP$', 'Springer': 'NNP', 'proceedings': 'NNS', 'publication': 'NN'}\n",
      "['I', 'am', 'very', 'grateful', 'for', 'the', 'full', 'support', 'of', 'the', 'professor', ',', 'for', 'our', 'Springer', 'proceedings', 'publication', '.']\n",
      "I: PRP\n",
      "am: BVP\n",
      "very: RB\n",
      "grateful: JJ\n",
      "for: IN\n",
      "the: DT\n",
      "full: JJ\n",
      "support: NN\n",
      "of: IN\n",
      "professor: NN\n",
      ",: PUNC\n",
      "our: PRP$\n",
      "Springer: NNP\n",
      "proceedings: NNS\n",
      "publication: NN\n",
      ".: PUNC\n",
      "Before\n",
      "I am very appreciated  the full support of the professor, for our Springer proceedings publication\n",
      "   \n",
      "   \n",
      "targetPOS: PRP\n",
      "currentPOS: PRP\n",
      "target word: I\n",
      "current word: I\n",
      "Length of tokens: 16\n",
      "New targetPOS: BVP\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 1\n",
      "targetPOS: BVP\n",
      "currentPOS: BVP\n",
      "target word: am\n",
      "current word: am\n",
      "Length of tokens: 16\n",
      "New targetPOS: RB\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 2\n",
      "targetPOS: RB\n",
      "currentPOS: RB\n",
      "target word: very\n",
      "current word: very\n",
      "Length of tokens: 16\n",
      "New targetPOS: JJ\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 3\n",
      "targetPOS: JJ\n",
      "currentPOS: VBN\n",
      "target word: grateful\n",
      "current word: appreciated\n",
      "Error found\n",
      "Rule 1\n",
      "   \n",
      "   \n",
      "current index1: 3\n",
      "targetPOS: JJ\n",
      "currentPOS: JJ\n",
      "target word: grateful\n",
      "current word: grateful\n",
      "Length of tokens: 16\n",
      "New targetPOS: IN\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 4\n",
      "targetPOS: IN\n",
      "currentPOS: DT\n",
      "target word: for\n",
      "current word: the\n",
      "Error found\n",
      "Rule 2\n",
      "   \n",
      "   \n",
      "current index1: 4\n",
      "targetPOS: IN\n",
      "currentPOS: IN\n",
      "target word: for\n",
      "current word: for\n",
      "Length of tokens: 17\n",
      "New targetPOS: DT\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 5\n",
      "targetPOS: DT\n",
      "currentPOS: DT\n",
      "target word: the\n",
      "current word: the\n",
      "Length of tokens: 17\n",
      "New targetPOS: JJ\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 6\n",
      "targetPOS: JJ\n",
      "currentPOS: JJ\n",
      "target word: full\n",
      "current word: full\n",
      "Length of tokens: 17\n",
      "New targetPOS: NN\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 7\n",
      "targetPOS: NN\n",
      "currentPOS: NN\n",
      "target word: support\n",
      "current word: support\n",
      "Length of tokens: 17\n",
      "New targetPOS: IN\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 8\n",
      "targetPOS: IN\n",
      "currentPOS: IN\n",
      "target word: of\n",
      "current word: of\n",
      "Length of tokens: 17\n",
      "New targetPOS: DT\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 9\n",
      "targetPOS: DT\n",
      "currentPOS: DT\n",
      "target word: the\n",
      "current word: the\n",
      "Length of tokens: 17\n",
      "New targetPOS: NN\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 10\n",
      "targetPOS: NN\n",
      "currentPOS: NN\n",
      "target word: professor\n",
      "current word: professor\n",
      "Length of tokens: 17\n",
      "New targetPOS: PUNC\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 11\n",
      "targetPOS: PUNC\n",
      "currentPOS: PUNC\n",
      "target word: ,\n",
      "current word: ,\n",
      "Length of tokens: 17\n",
      "New targetPOS: IN\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 12\n",
      "targetPOS: IN\n",
      "currentPOS: IN\n",
      "target word: for\n",
      "current word: for\n",
      "Length of tokens: 17\n",
      "New targetPOS: PRP$\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 13\n",
      "targetPOS: PRP$\n",
      "currentPOS: PRP$\n",
      "target word: our\n",
      "current word: our\n",
      "Length of tokens: 17\n",
      "New targetPOS: NNP\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 14\n",
      "targetPOS: NNP\n",
      "currentPOS: NNP\n",
      "target word: Springer\n",
      "current word: Springer\n",
      "Length of tokens: 17\n",
      "New targetPOS: NNS\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 15\n",
      "targetPOS: NNS\n",
      "currentPOS: NNS\n",
      "target word: proceedings\n",
      "current word: proceedings\n",
      "Length of tokens: 17\n",
      "New targetPOS: NN\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 16\n",
      "targetPOS: NN\n",
      "currentPOS: NN\n",
      "target word: publication\n",
      "current word: publication\n",
      "Length of tokens: 18\n",
      "New targetPOS: PUNC\n",
      "Proceeding...\n",
      "   \n",
      "   \n",
      "current index1: 17\n",
      "targetPOS: PUNC\n",
      "currentPOS: PLACEHOLDER\n",
      "target word: .\n",
      "current word: _\n",
      "Error found\n",
      "Rule 3\n",
      "   \n",
      "   \n",
      "current index1: 18\n",
      "   \n",
      "   \n",
      "After\n",
      "I am very grateful for the full support of the professor, for our Springer proceedings publication.\n",
      "TREE\n",
      "                                            S                                                                             \n",
      "  __________________________________________|_________________________________________________________________________     \n",
      " |       VP                                                                                                           |   \n",
      " |    ___|_________________                                                                                           |    \n",
      " |   |   |      |          PP                                                                                         |   \n",
      " |   |   |      |       ___|__________                                                                                |    \n",
      " |   |   |      |      |              NP                                                                              |   \n",
      " |   |   |      |      |    __________|________________                                                               |    \n",
      " |   |   |      |      |   |   |      |                PP                                                             |   \n",
      " |   |   |      |      |   |   |      |      __________|____________                                                  |    \n",
      " |   |   |      |      |   |   |      |     |                       NP                                                |   \n",
      " |   |   |      |      |   |   |      |     |    ___________________|_________                                        |    \n",
      " |   |   |      |      |   |   |      |     |   |      |       |              PP                                      |   \n",
      " |   |   |      |      |   |   |      |     |   |      |       |     _________|______                                 |    \n",
      " |   |   |      |      |   |   |      |     |   |      |       |    |                NP                               |   \n",
      " |   |   |      |      |   |   |      |     |   |      |       |    |    ____________|_______                         |    \n",
      " |   |   |      |      |   |   |      |     |   |      |       |    |   |                    N                        |   \n",
      " |   |   |      |      |   |   |      |     |   |      |       |    |   |      ______________|_______                 |    \n",
      " NP  |   |      |      |   |   |      |     |   |      |       |    |   |     |                      N                |   \n",
      " |   |   |      |      |   |   |      |     |   |      |       |    |   |     |               _______|_______         |    \n",
      "PRP VBP  RB     JJ     IN Det  JJ     N     IN Det     N     COMMA  IN PRP    JJ             JJ              N      PERIOD\n",
      " |   |   |      |      |   |   |      |     |   |      |       |    |   |     |              |               |        |    \n",
      " I   am very grateful for the full support  of the professor   ,   for our Springer     proceedings     publication   .   \n",
      "\n",
      "TREE DONE\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "#simple regular expression, extract tokens from sentence.\n",
    "pattern = r\"\\w+|[.,!?;:'\\\"-]\"\n",
    "text_test = \"I am very appreciated  the full support of the professor, for our Springer proceedings publication\"\n",
    "tokens_test = re.findall(pattern, text_test)\n",
    "print(tokens_test)\n",
    "\n",
    "#assigning roles to each token.\n",
    "roles_test = {\n",
    "    tokens_test[0]: \"PRP\",      # \"I\" = Personal Pronoun\n",
    "    tokens_test[1]: \"BVP\",      # \"am\" = Verb, Present, (Non-3rd person singular)\n",
    "    tokens_test[2]: \"RB\",       # \"very\" = Adverb\n",
    "    tokens_test[3]: \"VBN\",      # \"appreciated\" = Verb, Past Participle\n",
    "    tokens_test[4]: \"DT\",       # \"the\" = Determiner\n",
    "    tokens_test[5]: \"JJ\",       # \"full\" = Adjective\n",
    "    tokens_test[6]: \"NN\",       # \"support\" = Noun\n",
    "    tokens_test[7]: \"IN\",       # \"of\" = Preposition\n",
    "    tokens_test[8]: \"DT\",       # \"the\" = Determiner\n",
    "    tokens_test[9]: \"NN\",       # \"professor\" = Noun\n",
    "    tokens_test[10]: \"PUNC\",    # \",\" = Punctuation\n",
    "    tokens_test[11]: \"IN\",      # \"for\" = Preposition\n",
    "    tokens_test[12]: \"PRP$\",    # \"our\" = Possessive Pronoun\n",
    "    tokens_test[13]: \"NNP\",     # \"Springer\" = Proper Noun\n",
    "    tokens_test[14]: \"NNS\",     # \"proceedings\" = Noun, Plural\n",
    "    tokens_test[15]: \"NN\"       # \"publication\" = Noun\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print(\"ROLES\")\n",
    "print(roles_test)\n",
    "\n",
    "#The CORRECT sentence\n",
    "text_reference = \"I am very grateful for the full support of the professor, for our Springer proceedings publication.\"\n",
    "tokens_reference = re.findall(pattern, text_reference)\n",
    "print(tokens_reference)\n",
    "\n",
    "#assigning roles to each token.\n",
    "roles_reference = {\n",
    "    tokens_reference[0]: \"PRP\",\n",
    "    tokens_reference[1]: \"BVP\",\n",
    "    tokens_reference[2]: \"RB\",\n",
    "    tokens_reference[3]: \"JJ\",\n",
    "    tokens_reference[4]: \"IN\",\n",
    "    tokens_reference[5]: \"DT\",\n",
    "    tokens_reference[6]: \"JJ\",\n",
    "    tokens_reference[7]: \"NN\",\n",
    "    tokens_reference[8]: \"IN\",\n",
    "    tokens_reference[9]: \"DT\",\n",
    "    tokens_reference[10]: \"NN\",\n",
    "    tokens_reference[11]: \"PUNC\",\n",
    "    tokens_reference[12]: \"IN\",\n",
    "    tokens_reference[13]: \"PRP$\",\n",
    "    tokens_reference[14]: \"NNP\",\n",
    "    tokens_reference[15]: \"NNS\",\n",
    "    tokens_reference[16]: \"NN\",\n",
    "    tokens_reference[17]: \"PUNC\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Print word-role mappings\n",
    "for word, role in roles_reference.items():\n",
    "    print(f\"{word}: {role}\")\n",
    "\n",
    "\n",
    "#Get the POS of a word (a word from the wrong sentence)\n",
    "def POS(word):\n",
    "    return(roles_reference[word])\n",
    "\n",
    "\n",
    "index1 = 0\n",
    "targetPOS = roles_reference[tokens_reference[index1]]    #What POS tag this word is supposed to have.\n",
    "def FSA():\n",
    "    global index1, targetPOS, tokens_test, tokens_reference, roles_test, roles_reference\n",
    "\n",
    "    #Append a placeholder at the end, so that tokens_test has a valid \"tokens_test[27]\" to work on, so that no errors are caused.\n",
    "    if index1 == 16 and tokens_test[index1] == \"publication\":\n",
    "        tokens_test.append(\"_\")\n",
    "        roles_test[\"_\"] = \"PLACEHOLDER\"\n",
    "\n",
    "    print(f\"targetPOS: {targetPOS}\")\n",
    "    print(f\"currentPOS: {roles_test[tokens_test[index1]]}\")\n",
    "    print(f\"target word: {tokens_reference[index1]}\")\n",
    "    print(f\"current word: {tokens_test[index1]}\")\n",
    "\n",
    "    #Compare targetPOS to the ACTUAL POS that this word has. Are they the same? \n",
    "    #If so, then there are no errors, so we move on to next word.\n",
    "    if targetPOS == roles_test[tokens_test[index1]]:    \n",
    "        #Go to next state\n",
    "\n",
    "        print(f\"Length of tokens: {len(tokens_test)}\")\n",
    "        if index1 < len(tokens_test) - 1:\n",
    "            targetPOS = roles_reference[tokens_reference[index1 + 1]]\n",
    "            print(f\"New targetPOS: {targetPOS}\")\n",
    "        print(\"Proceeding...\")\n",
    "       \n",
    "\n",
    "    #The POS tags are different. Use one of the rules below to fix this error.\n",
    "    else:   \n",
    "        print(\"Error found\")\n",
    "        if tokens_test[index1] == \"appreciated\":  #Rule 1\n",
    "\n",
    "            print(\"Rule 1\")\n",
    "            tokens_test[index1] = \"grateful\"\n",
    "            roles_test[tokens_test[index1]] = \"JJ\"\n",
    "            index1 -= 1     #This is not required. It is only used to show the corrected version while printing. The fix still takes place regardless.\n",
    "\n",
    "        elif tokens_test[index1 - 1] == \"grateful\" and tokens_test[index1] != \"for\":  #Rule 2\n",
    "\n",
    "            print(\"Rule 2\")\n",
    "            tokens_test.insert(index1, \"for\")\n",
    "            index1 -= 1    #This is not required. It is only used to show the corrected version while printing. The fix still takes place regardless.\n",
    "\n",
    "        elif tokens_test[index1] == \"_\" and index1 == 17:   #Rule 3\n",
    "            print(\"Rule 3\")\n",
    "            tokens_test[index1] = \".\"\n",
    "\n",
    "        else:\n",
    "            print(\"No matching rule.\")\n",
    "            print(tokens_test[index1])\n",
    "\n",
    "    index1 += 1\n",
    "    print(\"   \")\n",
    "    print(\"   \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def arrayToText(array):\n",
    "    sentence = \"\"\n",
    "    finalarray = []\n",
    "    i = 0\n",
    "    while i < len(array) - 1:\n",
    "        finalarray.append(array[i])\n",
    "        if POS(array[i + 1]) != \"PUNC\": #Add a space after a word, ONLY if the next word is NOT a punctuation. (We want \"Hello, World!\", and not \"Hello , World !\".)\n",
    "            finalarray.append(\" \")\n",
    "        i += 1\n",
    "        \n",
    "    finalarray.append(array[len(array) - 1])    \n",
    "    sentence = \"\".join(finalarray)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "#FSA will run in a while loop. While index1 <= 17.\n",
    "\n",
    "print(\"Before\")\n",
    "print(text_test)\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "\n",
    "while index1 <= len(tokens_reference) - 1:\n",
    "    FSA()\n",
    "    print(f\"current index1: {index1}\")\n",
    "\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "print(\"After\")\n",
    "print(arrayToText(tokens_test))\n",
    "\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\n",
    "    \"\"\" \n",
    "    S -> NP VP PERIOD\n",
    "    NP -> PRP | PRP N | Det N COMMA PP | Det JJ N PP\n",
    "    VP -> VBP RB JJ PP\n",
    "    PP -> IN NP\n",
    "    PRP -> 'I' | 'our'\n",
    "    N -> 'support' | 'professor' | 'publication' | JJ N\n",
    "    Det -> 'the'\n",
    "    JJ -> 'grateful' | 'full' | 'Springer' | 'proceedings'\n",
    "    VBP -> 'am' \n",
    "    RB -> 'very'\n",
    "    IN -> 'for' | 'of'\n",
    "    COMMA -> ','\n",
    "    PERIOD -> '.'\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "    \n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "treesfound = 0\n",
    "\n",
    "print(\"TREE\")\n",
    "for tree in parser.parse(tokens_test):\n",
    "    tree.pretty_print()\n",
    "\n",
    "\n",
    "print(\"TREE DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee90540",
   "metadata": {},
   "source": [
    "# Text 2's Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a040e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "#simple regular expression, extract tokens from sentence.\n",
    "pattern2 = r\"\\w+|[.,!?;:'\\\"-]\"\n",
    "text_test = \"Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation.\"\n",
    "tokens_test = re.findall(pattern2, text_test)\n",
    "#print(tokens)\n",
    "\n",
    "#assigning roles to each token.\n",
    "roles_test = {\n",
    "    tokens_test[0]: \"RB\",\n",
    "    tokens_test[1]: \"PUNC\",\n",
    "    tokens_test[2]: \"PRP\",\n",
    "    tokens_test[3]: \"BVP\",\n",
    "    tokens_test[4]: \"DT\",\n",
    "    tokens_test[5]: \"NN\",\n",
    "    tokens_test[6]: \"PUNC\",\n",
    "    tokens_test[7]: \"IN\",\n",
    "    tokens_test[8]: \"NN\",\n",
    "    tokens_test[9]: \"NN\",\n",
    "    tokens_test[10]: \"CC\",\n",
    "    tokens_test[11]: \"RBR\",\n",
    "    tokens_test[12]: \"NN\",\n",
    "    tokens_test[13]: \"IN\",\n",
    "    tokens_test[14]: \"JJ\",\n",
    "    tokens_test[15]: \"NNS\",\n",
    "    tokens_test[16]: \"PUNC\",\n",
    "    tokens_test[17]: \"PRP\",\n",
    "    tokens_test[18]: \"RB\",\n",
    "    tokens_test[19]: \"VBD\",\n",
    "    tokens_test[20]: \"JJS\",\n",
    "    tokens_test[21]: \"IN\",\n",
    "    tokens_test[22]: \"NN\",\n",
    "    tokens_test[23]: \"CC\",\n",
    "    tokens_test[24]: \"NN\",\n",
    "    tokens_test[25]: \"PUNC\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Test Tokens\")\n",
    "#Print word-role mappings\n",
    "for word, role in roles_test.items():\n",
    "    print(f\"{word}: {role}\")\n",
    "\n",
    "\n",
    "#The CORRECT sentence\n",
    "\n",
    "text_reference = \"Anyway, I believe the team, although a bit delayed and less communicative in recent days, really tried their best to cooperate on the paper.\"\n",
    "tokens_reference = re.findall(pattern2, text_reference)\n",
    "\n",
    "\n",
    "#assigning roles to each token.\n",
    "roles_reference = {\n",
    "    tokens_reference[0]: \"RB\",      #Anyway\n",
    "    tokens_reference[1]: \"PUNC\",    #,\n",
    "    tokens_reference[2]: \"PRP\",     #I\n",
    "    tokens_reference[3]: \"BVP\",     #believe\n",
    "    tokens_reference[4]: \"DT\",      #the\n",
    "    tokens_reference[5]: \"NN\",      #team\n",
    "    tokens_reference[6]: \"PUNC\",    #,\n",
    "    tokens_reference[7]: \"IN\",      #although\n",
    "    tokens_reference[8]: \"DT\",      #a\n",
    "    tokens_reference[9]: \"NN\",      #bit\n",
    "    tokens_reference[10]: \"JJ\",     #delayed\n",
    "    tokens_reference[11]: \"CC\",     #and\n",
    "    tokens_reference[12]: \"RBR\",    #less\n",
    "    tokens_reference[13]: \"JJ\",     #communicative\n",
    "    tokens_reference[14]: \"IN\",     #in\n",
    "    tokens_reference[15]: \"JJ\",     #recent\n",
    "    tokens_reference[16]: \"NNS\",    #days\n",
    "    tokens_reference[17]: \"PUNC\",   #,\n",
    "    tokens_reference[18]: \"RB\",     #really\n",
    "    tokens_reference[19]: \"VBD\",    #tried\n",
    "    tokens_reference[20]: \"PRP$\",   #their\n",
    "    tokens_reference[21]: \"JJS\",    #best\n",
    "    tokens_reference[22]: \"TO\",     #to\n",
    "    tokens_reference[23]: \"VB\",     #cooperate\n",
    "    tokens_reference[24]: \"IN\",     #on\n",
    "    tokens_reference[25]: \"DT\",     #the\n",
    "    tokens_reference[26]: \"NN\",     #paper\n",
    "    tokens_reference[27]: \"PUNC\"    #.\n",
    "}\n",
    "\n",
    "\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "print(\"Reference Tokens\")\n",
    "\n",
    "\n",
    "print(tokens_reference)\n",
    "\n",
    "\n",
    "#Get the POS of a word (a word from the wrong sentence)\n",
    "def POS(word):\n",
    "    return roles_reference[word]\n",
    "\n",
    "\n",
    "index1 = 0\n",
    "targetPOS = roles_reference[tokens_reference[index1]]\n",
    "def FSA():\n",
    "    global index1, targetPOS, tokens_test, tokens_reference, roles_test, roles_reference\n",
    "\n",
    "    #Append a placeholder at the end, so that tokens_test has a valid \"tokens_test[27]\" to work on, so that no errors are caused.\n",
    "    if index1 == 26 and tokens_test[index1] == \"paper\":\n",
    "        tokens_test.append(\"_\")\n",
    "        roles_test[\"_\"] = \"PLACEHOLDER\"\n",
    "        \n",
    "\n",
    "    print(f\"targetPOS: {targetPOS}\")\n",
    "    print(f\"currentPOS: {roles_test[tokens_test[index1]]}\")\n",
    "    print(f\"target word: {tokens_reference[index1]}\")\n",
    "    print(f\"current word: {tokens_test[index1]}\")\n",
    "    print(f\"Length of tokens: {len(tokens_test)}\")\n",
    "\n",
    "    if targetPOS == roles_test[tokens_test[index1]]:\n",
    "        \n",
    "        if tokens_test[index1] == \"at\" and tokens_test[index1 + 1] == \"recent\" and tokens_test[index1 + 2] == \"days\":\n",
    "            print(\"Rule 3\")\n",
    "            tokens_test[index1] = \"in\"\n",
    "\n",
    "\n",
    "        #Go to next state\n",
    "        \n",
    "        if index1 < len(tokens_test) - 1:\n",
    "            targetPOS = roles_reference[tokens_reference[index1 + 1]]\n",
    "            print(f\"New targetPOS: {targetPOS}\")\n",
    "            print(\"Proceeding...\")\n",
    "        \n",
    "            \n",
    "       \n",
    "\n",
    "\n",
    "    else:   \n",
    "        print(\"Error found\")\n",
    "        if tokens_test[index1] == \"communication\":  #Rule 1\n",
    "\n",
    "            print(\"Rule 1\")\n",
    "            tokens_test[index1] = \"communicative\"\n",
    "            roles_test[tokens_test[index1]] = \"JJ\"\n",
    "            index1 -= 1     #This is not required. It is only used to show the corrected version while printing. The fix still takes place regardless.\n",
    "\n",
    "        elif tokens_test[index1] == \"they\":  #Rule 4\n",
    "            print(\"Rule 4\")\n",
    "            tokens_test.remove(\"they\")\n",
    "\n",
    "            index1 -= 1    #This is not required. It is only used to show the corrected version while printing. The fix still takes place regardless.\n",
    "\n",
    "        elif tokens_test[index1] == \"bit\" and tokens_test[index1 - 1] != \"a\":   #Rule 5\n",
    "            print(\"Rule 5\")\n",
    "            tokens_test.insert(index1, \"a\")\n",
    "            roles_test[\"a\"] = \"DT\"\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"delay\" and targetPOS == \"JJ\":   #Rule 6\n",
    "            print(\"Rule 6\")\n",
    "            tokens_test[index1] = \"delayed\"\n",
    "            roles_test[\"delayed\"] = \"JJ\"\n",
    "\n",
    "            #index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"best\" and tokens_test[index1 - 1] != \"their\":   #Rule 7\n",
    "            print(\"Rule 7\")\n",
    "            tokens_test.insert(index1, \"their\")\n",
    "            roles_test[\"their\"] = \"PRP$\"\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"for\":   #Rule 8\n",
    "            print(\"Rule 8\")\n",
    "            tokens_test[index1] = \"to\"\n",
    "            roles_test[\"to\"] = \"TO\"\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"paper\":   #Rule 9\n",
    "            print(\"Rule 9\")\n",
    "            tokens_test[index1] = \"cooperate\"\n",
    "            roles_test[\"cooperate\"] = \"VB\"\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"and\" and tokens_test[index1 - 1] == \"cooperate\":   #Rule 10\n",
    "            print(\"Rule 10\")\n",
    "            tokens_test[index1] = \"on\"\n",
    "            roles_test[\"on\"] = \"IN\"\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"cooperation\":   #Rule 11\n",
    "            print(\"Rule 11\")\n",
    "            tokens_test[index1] = \"the\"\n",
    "            roles_test[\"the\"] = \"DT\"\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \".\":   #Rule 12\n",
    "            print(\"Rule 12\")\n",
    "            tokens_test[index1] = \"paper\"\n",
    "\n",
    "            #tokens_test.append(\".\")\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        elif tokens_test[index1] == \"_\" and index1 == 27:   #Rule 13\n",
    "            print(\"Rule 13\")\n",
    "            tokens_test[index1] = \".\"\n",
    "\n",
    "            #tokens_test.append(\".\")\n",
    "\n",
    "            index1 -= 1\n",
    "\n",
    "        else:\n",
    "            print(\"No matching rule.\")\n",
    "            print(tokens_test[index1])\n",
    "\n",
    "    index1 += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"   \")\n",
    "    print(\"   \")\n",
    "\n",
    "\n",
    "def arrayToText(array):\n",
    "    sentence = \"\"\n",
    "    finalarray = []\n",
    "    i = 0\n",
    "    while i < len(array) - 1:\n",
    "        finalarray.append(array[i])\n",
    "        if POS(array[i + 1]) != \"PUNC\":\n",
    "            finalarray.append(\" \")\n",
    "        i += 1\n",
    "        \n",
    "    finalarray.append(array[len(array) - 1])    \n",
    "    sentence = \"\".join(finalarray)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FSA will run in a while loop. While index1 <= 15.\n",
    "\n",
    "print(\"Before\")\n",
    "print(text_test)\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "\n",
    "while index1 <= 27:\n",
    "    FSA()\n",
    "    print(f\"current index1: {index1}\")\n",
    "\n",
    "print(\"   \")\n",
    "print(\"   \")\n",
    "print(\"After\")\n",
    "\n",
    "print(tokens_test)\n",
    "print(arrayToText(tokens_test))\n",
    "\n",
    "#   \"Anyway, I believe the team, although a bit delayed and less communicative in recent days, really tried their best to cooperate on the paper.\"\n",
    "\n",
    "grammar = nltk.CFG.fromstring(\n",
    "    \"\"\" \n",
    "    S -> RB COMMA NP VP | NP VP PERIOD\n",
    "    NP -> PRP | DT NN | DT NN COMMA | JJ NN\n",
    "    VP -> VB | VB S | RB VB PSP JJ TO_VP | SUB_CL VP\n",
    "    TO_VP -> TO VP PP\n",
    "    PP -> IN NP\n",
    "    SUB_CL -> IN JJP_GROUP PP COMMA\n",
    "    JJP_GROUP -> JJP | JJP CC JJP\n",
    "    JJP -> DT NN JJ | RB JJ\n",
    "\n",
    "    RB -> 'Anyway' | 'less' | 'really'\n",
    "    PRP -> 'I'\n",
    "    DT -> 'the' | 'a'\n",
    "    NN -> 'team' | 'bit' | 'days' | 'paper'\n",
    "    JJ -> 'delayed' | 'communicative' | 'recent' | 'best'\n",
    "    VB -> 'believe' | 'tried' | 'cooperate'\n",
    "    PSP -> 'their'\n",
    "    TO -> 'to'\n",
    "    IN -> 'on' | 'although' | 'in'\n",
    "    CC -> 'and'\n",
    "    COMMA -> ','\n",
    "    PERIOD -> '.'\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "    \n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "treesfound = 0\n",
    "\n",
    "print(\"TREE\")\n",
    "for tree in parser.parse(tokens_test):\n",
    "    tree.pretty_print()\n",
    "\n",
    "\n",
    "print(\"TREE DONE\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
