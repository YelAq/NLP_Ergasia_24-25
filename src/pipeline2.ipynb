{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import nltk"
      ],
      "metadata": {
        "id": "wiL79ljbf3a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Κατέβασε punkt για sentence tokenization\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFomAfdGf7RF",
        "outputId": "37afae62-20a5-4d0f-ca9b-bcb06599ff8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar_model_name = \"prithivida/grammar_error_correcter_v1\"\n",
        "grammar_tokenizer = AutoTokenizer.from_pretrained(grammar_model_name)\n",
        "grammar_model = AutoModelForSeq2SeqLM.from_pretrained(grammar_model_name)\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "grammar_model = grammar_model.to(torch_device)\n",
        "\n",
        "def correct_grammar(text: str) -> str:\n",
        "    inputs = grammar_tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=256).to(torch_device)\n",
        "    outputs = grammar_model.generate(inputs, max_length=256, num_beams=4, early_stopping=True)\n",
        "    corrected_text = grammar_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected_text"
      ],
      "metadata": {
        "id": "fFlI66R0f_Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pegasus paraphraser ---\n",
        "model_name = \"tuner007/pegasus_paraphrase\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def paraphrase_sentence(sentence: str, num_return_sequences: int = 1) -> list[str]:\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=60).to(torch_device)\n",
        "    outputs = model.generate(**inputs, max_length=60, num_beams=5, num_return_sequences=num_return_sequences)\n",
        "    paraphrases = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return paraphrases\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by-htYDbgDHk",
        "outputId": "980f8ad1-cdce-4164-a755-fa3e789e566f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ολοκληρωμένη ροή ---\n",
        "def process_text(text: str) -> str:\n",
        "    sentences = sent_tokenize(text)\n",
        "    corrected_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        print(\"\\nOriginal:\", sentence)\n",
        "        corrected = correct_grammar(sentence)\n",
        "        print(\"Grammar Corrected:\", corrected)\n",
        "        paraphrased_list = paraphrase_sentence(corrected, num_return_sequences=1)\n",
        "        paraphrased = paraphrased_list[0] if paraphrased_list else corrected\n",
        "        print(\"Paraphrased:\", paraphrased, \"\\n\")\n",
        "        corrected_sentences.append(paraphrased)\n",
        "\n",
        "    return \" \".join(corrected_sentences)\n"
      ],
      "metadata": {
        "id": "y3tGkBXwgGj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Example usage ---\n",
        "text = \"\"\"\n",
        "During our final discuss, I told him about the new submission — the one we were waiting since\n",
        "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
        "maybe editor?\n",
        "Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
        "tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance\n",
        "and efforts until the Springer link came finally last week, I think.\n",
        "Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
        "he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
        "Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future\n",
        "targets\"\"\"\n",
        "\n",
        "result = process_text(text)\n",
        "print(\"\\n\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUpQ2YPLgJjT",
        "outputId": "20975998-2f7e-48b3-fc21-31d9ba92e83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original: \n",
            "During our final discuss, I told him about the new submission — the one we were waiting since\n",
            "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
            "maybe editor?\n",
            "Grammar Corrected: During our final discuss, I told him about the new submission — the one we were waiting for since last autumn, but the updates were confusing as it did not include the full feedback from reviewer or maybe editor?\n",
            "Paraphrased: I told him about the new submission we were waiting for since last autumn, but the updates were confusing as it did not include the full feedback from reviewer or editor. \n",
            "\n",
            "\n",
            "Original: Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
            "tried best for paper and cooperation.\n",
            "Grammar Corrected: Anyway, I believe the team, although a bit delay and less communication in recent days, they really tried their best for paper and cooperation.\n",
            "Paraphrased: I think the team tried their best for paper and cooperation despite the recent delay and less communication. \n",
            "\n",
            "\n",
            "Original: We should be grateful, I mean all of us, for the acceptance\n",
            "and efforts until the Springer link came finally last week, I think.\n",
            "Grammar Corrected: We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think.\n",
            "Paraphrased: We should be thankful for the acceptance and efforts until the Springer link came last week, I think. \n",
            "\n",
            "\n",
            "Original: Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
            "he sending again.\n",
            "Grammar Corrected: Also, kindly remind me please, if the doctor still plans for the acknowledgments section edit before he sends again.\n",
            "Paraphrased: If the doctor still plans for the acknowledgments section to be edited before he sends again, please remind me. \n",
            "\n",
            "\n",
            "Original: Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
            "Grammar Corrected: Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
            "Paraphrased: I apologize if I missed that part final. \n",
            "\n",
            "\n",
            "Original: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future\n",
            "targets\n",
            "Grammar Corrected: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets.\n",
            "Paraphrased: Let's make sure all are safe and celebrate the outcome with coffee and targets. \n",
            "\n",
            "\n",
            " I told him about the new submission we were waiting for since last autumn, but the updates were confusing as it did not include the full feedback from reviewer or editor. I think the team tried their best for paper and cooperation despite the recent delay and less communication. We should be thankful for the acceptance and efforts until the Springer link came last week, I think. If the doctor still plans for the acknowledgments section to be edited before he sends again, please remind me. I apologize if I missed that part final. Let's make sure all are safe and celebrate the outcome with coffee and targets.\n"
          ]
        }
      ]
    }
  ]
}