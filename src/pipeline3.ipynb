{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f15f3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load spaCy for sentence splitting\u001b[39;00m\n\u001b[0;32m      5\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import spacy\n",
    "\n",
    "# Load spaCy for sentence splitting\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# OpenAI client\n",
    "client = OpenAI(api_key=\"to api mou\")\n",
    "\n",
    "# Sentence splitter\n",
    "def split_to_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "# GPT-4o Rewriter\n",
    "def gpt4o_rewrite(sentence):\n",
    "    prompt = (\n",
    "        f\"Fix the grammar, improve clarity, and paraphrase this sentence to sound natural and professional:\\n\\n{sentence}\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Full Pipeline\n",
    "def process_text(text):\n",
    "    results = []\n",
    "    for sentence in split_to_sentences(text):\n",
    "        rewritten = gpt4o_rewrite(sentence)\n",
    "        results.append((sentence, rewritten))\n",
    "    return results\n",
    "\n",
    "# Input Texts\n",
    "original_texts = {\n",
    "    \"Text1\": (\n",
    "        \"Today is our dragon boat festival, in our Chinese culture, to celebrate it \"\n",
    "        \"with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. \"\n",
    "        \"Thank your message to show our words to the doctor, as his next contract checking, to all of us. \"\n",
    "        \"I got this message to see the approved message. In fact, I have received the message from the \"\n",
    "        \"professor, to show me, this, a couple of days ago. I am very appreciated the full support of the \"\n",
    "        \"professor, for our Springer proceedings publication\"\n",
    "    ),\n",
    "    \"Text2\": (\n",
    "        \"During our final discuss, I told him about the new submission — the one we were waiting since \"\n",
    "        \"last autumn, but the updates was confusing as it not included the full feedback from reviewer or \"\n",
    "        \"maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, \"\n",
    "        \"they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance \"\n",
    "        \"and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, \"\n",
    "        \"if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see \"\n",
    "        \"that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate \"\n",
    "        \"the outcome with strong coffee and future targets\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Run pipeline on both texts\n",
    "for label, text in original_texts.items():\n",
    "    print(f\"\\n=== {label} ===\\n\")\n",
    "    output = process_text(text)\n",
    "    for original, rewritten in output:\n",
    "        print(\"Original:  \", original)\n",
    "        print(\"Rewritten:\", rewritten)\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
